{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__top\"></a>\n",
    "\n",
    "# Project  3 - Subreddit Classifier\n",
    "## Modeling and Conclusion\n",
    "General Assembly DSI CC7 Project 3\n",
    "<br>Anne Kerr - SF<br>\n",
    "Due April 5, 2019\n",
    "\n",
    "\n",
    "This notebook contains the following sections:\n",
    "\n",
    "-  [Loading and Preparing the Data](#section__Load_and_Prep)\n",
    "-  [Model Search](#section__Model_Search)\n",
    "-  [Final Model Tuning](#section__Model_Tuning)\n",
    "-  [Predictions and Evaluation](#section__Predictions)\n",
    "-  [Conclusion](#section__Conclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#Importing NumPy and Pandas.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler   #transformers\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Import Tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from pactools.grid_search import GridSearchCVProgressBar\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__Load_and_Prep\"></a>\n",
    "\n",
    "\n",
    "#### Read and Pre-process the Data\n",
    "We begin by reading the cleaned final dataset into a single dataframe. \n",
    "\n",
    "  \n",
    "Note: We already deleted duplicates and have no missing values for the selftext (from which we will derive the features for our model) or the subreddit name, our target.\n",
    "\n",
    "[back to top](#section__top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>travel</td>\n",
       "      <td>b6i1po</td>\n",
       "      <td>hey travellers in this weekly community discus...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.553775e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>travel</td>\n",
       "      <td>b7owfp</td>\n",
       "      <td>hi reddit my friends and i will be going on ou...</td>\n",
       "      <td>elysxan</td>\n",
       "      <td>1.554046e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>travel</td>\n",
       "      <td>b7ou42</td>\n",
       "      <td>had a free weekend looking for a day of hiking...</td>\n",
       "      <td>logflumepirate</td>\n",
       "      <td>1.554046e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>travel</td>\n",
       "      <td>b7q4dz</td>\n",
       "      <td>hi all a friend and i are heading to nepal fro...</td>\n",
       "      <td>jyeatbvg</td>\n",
       "      <td>1.554053e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>travel</td>\n",
       "      <td>b7pzbp</td>\n",
       "      <td>does anyone have any tips on ride sharing from...</td>\n",
       "      <td>ruffianrevolution</td>\n",
       "      <td>1.554052e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit      id                                            cleaned  \\\n",
       "0    travel  b6i1po  hey travellers in this weekly community discus...   \n",
       "1    travel  b7owfp  hi reddit my friends and i will be going on ou...   \n",
       "2    travel  b7ou42  had a free weekend looking for a day of hiking...   \n",
       "3    travel  b7q4dz  hi all a friend and i are heading to nepal fro...   \n",
       "4    travel  b7pzbp  does anyone have any tips on ride sharing from...   \n",
       "\n",
       "              author       created  ups  downs  \n",
       "0      AutoModerator  1.553775e+09   10      0  \n",
       "1            elysxan  1.554046e+09    5      0  \n",
       "2     logflumepirate  1.554046e+09    4      0  \n",
       "3           jyeatbvg  1.554053e+09    2      0  \n",
       "4  ruffianrevolution  1.554052e+09    2      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned_posts_all.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define the target class\n",
    "Due to eliminating duplicates and posts with no actual text we were left with fewer than hoped for in each class. If we make travel the positive class, and all others the negative class. We will have a more balanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['subreddit'].map(lambda x: 1 if x == 'travel' else 0)\n",
    "\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below that the dataset isn't perfectly balanced, but it isn't bad. Hopefully there will be enough data to create and test some good models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1039\n",
       "1     808\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Travel vs (Fitness, Wine, and Gardening)')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "df['target'].value_counts().plot(kind='bar', color=['gray'])\n",
    "\n",
    "plt.title('Travel vs (Fitness, Wine, and Gardening)', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Baseline Accuracy\n",
    "By simply predicting the majority class accuracy would be 56.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.562534\n",
       "1    0.437466\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Prep\n",
    "Next we set set up X and perform train_test_split so we have a dataset for training the models and one on which to test. We use random_state=42 as a seed to ensure the results can be reproduce. We stratify on y to ensure that we have a balance of our targt varable in both the training and the test data. This is particularly important if the data is unbalanced with respect to y, but in general a good idea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts: 1847, Training data: 1385, Test data: 462\n"
     ]
    }
   ],
   "source": [
    "print(f'Total posts: {df.shape[0]}, Training data: {X_train.shape[0]}, Test data: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section__Model_Search'></a>\n",
    "\n",
    "#### Model Approach\n",
    "\n",
    "For this project we will construct several pipelines use GridSearchCV to test various models and parameter combinations, searching for the best predictive model.\n",
    "\n",
    "I chose five different combinations. Each was constructed with a pipeline that consisted of a tokenizer (either CountVectorizer or Tfidif) and an estimator. I tried Logistic Regression Naive Bayes, KNN, Random Forest, and AdaBoost. The table below summarizes the reslts. The params columns listed the different best parameters as selected by the GridSearchCV. \n",
    "\n",
    "The best scores were models that chose 1500 as max features. I assume that if I let it select even more features the scores would get even better, but while these models may be good for Kaggle competitions, they do not seem particularly useful for predicting whether or not new posts are in the r/travel thread. For this reason I decided to look for the model that seemed to perform the best on smaller feature sets. \n",
    "\n",
    "From this information it looks like the best option is Naive Bayes with Tfidf, and the second best is LogisticRegression with CountVectorizer. I did not try Tfidif with Logistic Regression, or CountVectorizer with Naive Bayes. I will try these variations before deciding on a final model.\n",
    "\n",
    "*Note:* The model search performance is listed in two tables here. The first is simplified for the presentation, the second was useful to keep track of the parameter options that were chosen as best in each of the different models. I included only the differences.\n",
    "\n",
    "The pipelines and gridsearch for each combo appear after the tables.\n",
    "\n",
    "[back to top](#section__top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|attempt                            |train score|test score|difference|\n",
    "|-----------------------------------|------------|---------|----------|\n",
    "|CountVectorizer/Logistic Regression|.889       |.870      |.019      |\n",
    "|                                   |.896       |.885      |.011      |\n",
    "|Tfidif/Naive Bayes                 |.974       |.967      |.007      |   \n",
    "|                                   |.870       |.865      |.005      |\n",
    "|Tfidif/KNN                         |.836       |.807      |.029      |        \n",
    "|Tfidif/Random Forest               |.984       |.883      |.101      |\n",
    "|                                   |.957       |.831      |.126      |\n",
    "|Tfidif/AdaBoost                    |.981       |.883      |.098      |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__scores_grid\"></a>\n",
    "\n",
    "| Model  |  Params  |  Training/Test Scores    |\n",
    "| ------ | -------- | ----------------| ---------------|\n",
    "|[Logistic Regression with CountVectorizer](#section__lr) | 'cvec__max_features': 1500, 'cvec__min_df': 5  |Train Score GS1A: 0.9992779783393502|\n",
    "|  |     |Test Score GS1A: 0.9588744588744589|\n",
    "|  |     |-----------------------------------|\n",
    "|  | 'cvec__max_features': 50, 'cvec__min_df': 2 |Train Score GS1B: 0.8967509025270758\n",
    "|  |  |Test Score GS1B: 0.8852813852813853|\n",
    "|  |     |-----------------------------------|\n",
    "|[Naive Bayes with Tfidf](#section__nbayes) |'tfidf__max_df': 0.9, 'tfidf__max_features': 1500, |Train Score GS2A: 0.9740072202166065|\n",
    "|  |  |Test Score GS2A: 0.9675324675324676|\n",
    "|  |     |-----------------------------------|\n",
    "|  |'tfidf__max_df': 0.75, 'tfidf__max_features': 50|Train Score GS2B: 0.8700361010830325|\n",
    "|  |  |Test Score BS2B: 0.8658008658008658|\n",
    "|  |     |-----------------------------------|\n",
    "|[KNN with Tfidf](#section__knn)  |'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3|Train Score GS3A: 0.836101083032491|\n",
    "|  |  |Test Score GS3A: 0.8073593073593074|\n",
    "|  |     |-----------------------------------|\n",
    "|  |(Same)|Train Score GS3B: 0.836101083032491|\n",
    "|  |  |Test Score GS3B: 0.8073593073593074|\n",
    "|  |     |-----------------------------------|\n",
    "|[Random Forestm with Tfidf](#section__random_forest)   | 'rf__max_depth': None, 'rf__max_features': 'auto', 'rf__n_estimators': 50, 'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 2 |Train Score GS4A: 0.9848375451263538|\n",
    "|  |  |Test Score GS4A: 0.8831168831168831|\n",
    "|  |     |-----------------------------------|\n",
    "|  |'rf__max_depth': 5, 'rf__max_features': 50, 'rf__n_estimators': 10, 'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3  |Train Score GS4B: 0.8570397111913357|\n",
    "|  |  |Test Score GS4B: 0.8311688311688312|\n",
    "|  |     |-----------------------------------|\n",
    "|[ADA with Tfidif](#section__ada)  | 'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3 |Train Score GS5A: 0.9010830324909748|\n",
    "|  |  |Test Score GS5A: 0.8831168831168831|\n",
    "|  |     |-----------------------------------|\n",
    "|  | (same) |Train Score GS5B: 0.9010830324909748\n",
    "|  |  |Test Score GS5B: 0.8831168831168831|\n",
    "|  |     |-----------------------------------|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__lr\"></a>\n",
    "#### Logistic Regression with CountVectorizer\n",
    "\n",
    "[back](#section__scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with count vectorizer\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),   #count vectorizor\n",
    "    ('lr', LogisticRegression())     #model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best.score_: 0.9494584837545126\n",
      "gs.best.params_: {'cvec__max_df': 0.75, 'cvec__max_features': 1500, 'cvec__min_df': 5, 'cvec__stop_words': 'english', 'lr__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=1500, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "       ..., penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__max_features': [50, 100, 500, 1000, 1500],      #iterate over these options to see what is best\n",
    "    'cvec__min_df': [2,3,5],\n",
    "    'cvec__max_df': [.75, .8, .9, .95],\n",
    "    'lr__random_state': [42]\n",
    "    ##### note you could add 'cvec_tokenizer' : [None, custom_tokenizer]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3)\n",
    "gs.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'gs.best.score_: {gs.best_score_}') # cross_val_score\n",
    "print(f'gs.best.params_: {gs.best_params_}')\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS1A: 0.9992779783393502\n",
      "Test Score GS1A: 0.9588744588744589\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS1A: {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score GS1A: {gs.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs.best.score_: 0.8801444043321299\n",
      "gs.best.params_: {'cvec__max_df': 0.75, 'cvec__max_features': 50, 'cvec__min_df': 2, 'cvec__stop_words': 'english', 'lr__random_state': 42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        s..., penalty='l2', random_state=42, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "    'cvec__min_df': [2,3,5],\n",
    "    'cvec__max_df': [.75, .8, .9, .95],\n",
    "    'lr__random_state': [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3)\n",
    "gs.fit(X_train, y_train) # Also does cv in the background\n",
    "\n",
    "print(f'gs.best.score_: {gs.best_score_}') # cross_val_score\n",
    "print(f'gs.best.params_: {gs.best_params_}')\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS1B: 0.8967509025270758\n",
      "Test Score GS1B: 0.8852813852813853\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS1B: {gs.score(X_train,y_train)}')\n",
    "print(f'Test Score GS1B: {gs.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__nbayes\"></a>\n",
    "#### Naive Bayes with Tfidf\n",
    "[back](#section__scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes with Tfidf\n",
    "pipe2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor  \n",
    "    ('mnb', MultinomialNB())        #model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs2.best.score_: 0.9566787003610109\n",
      "gs2.best.params_: {'tfidf__max_df': 0.9, 'tfidf__max_features': 1500, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=1500, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...rue,\n",
       "        vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2 = {\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'tfidf__max_features': [1000, 1500],      #iterate over these options to see what is best\n",
    "        'tfidf__min_df': [2,3],\n",
    "        'tfidf__max_df': [.9, .95]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe2, param_grid=params2, cv=3)\n",
    "gs2.fit(X_train, y_train) # Also does cv in the background\n",
    "\n",
    "print(f'gs2.best.score_: {gs2.best_score_}') # cross_val_score\n",
    "print(f'gs2.best.params_: {gs2.best_params_}')\n",
    "gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS2A: 0.9740072202166065\n",
      "Test Score GS2A: 0.9675324675324676\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS2A: {gs2.score(X_train,y_train)}')\n",
    "print(f'Test Score GS2A: {gs2.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs2.best.score_: 0.8584837545126354\n",
      "gs2.best.params_: {'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...rue,\n",
       "        vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2 = {\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "        'tfidf__min_df': [2, 3, 5],\n",
    "        'tfidf__max_df': [.75, .8, .9, .95]\n",
    "}\n",
    "gs2 = GridSearchCV(pipe2, param_grid=params2, cv=3)\n",
    "gs2.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'gs2.best.score_: {gs2.best_score_}') # cross_val_score\n",
    "print(f'gs2.best.params_: {gs2.best_params_}')\n",
    "gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS2b: 0.8700361010830325\n",
      "Test Score BS2b: 0.8658008658008658\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS2b: {gs2.score(X_train,y_train)}')\n",
    "print(f'Test Score BS2b: {gs2.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__knn\"></a>\n",
    "#### KNN with Tfidf\n",
    "[back](#section__scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with Tfidf\n",
    "pipe3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor  \n",
    "    ('knn', KNeighborsClassifier(n_neighbors=20))        #model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...i',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'tfidf__stop_words': [None, 'english'], 'tfidf__max_features': [10, 25, 50], 'tfidf__min_df': [2, 3, 5], 'tfidf__max_df': [0.75, 0.8, 0.9, 0.95]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params3 = {\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "        'tfidf__min_df': [2, 3, 5],\n",
    "        'tfidf__max_df': [.75, .8, .9, .95]\n",
    "}\n",
    "gs3 = GridSearchCV(pipe3, param_grid=params3, cv=3)\n",
    "gs3.fit(X_train, y_train) # Also does cv in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs3.best.score_: 0.779783393501805\n",
      "gs3.best.params_: {'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...i',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'gs3.best.score_: {gs3.best_score_}') # cross_val_score\n",
    "print(f'gs3.best.params_: {gs3.best_params_}')\n",
    "gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS3A: 0.836101083032491\n",
      "Test Score GS3A: 0.8073593073593074\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS3A: {gs3.score(X_train,y_train)}')\n",
    "print(f'Test Score GS3A: {gs3.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs3.best.score_: 0.779783393501805\n",
      "gs3.best.params_: {'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...i',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params3 = {\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "        'tfidf__min_df': [2, 3, 5],\n",
    "        'tfidf__max_df': [.75, .8, .9]\n",
    "}\n",
    "gs3 = GridSearchCV(pipe3, param_grid=params3, cv=3)\n",
    "gs3.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'gs3.best.score_: {gs3.best_score_}') # cross_val_score\n",
    "print(f'gs3.best.params_: {gs3.best_params_}')\n",
    "gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS3B: 0.836101083032491\n",
      "Test Score GS3B: 0.8073593073593074\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS3B: {gs3.score(X_train,y_train)}')\n",
    "print(f'Test Score GS3B: {gs3.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__random_forest\"></a>\n",
    "#### Random Forestm with Tfidf\n",
    "[back](#section__scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with Tfidf\n",
    "pipe4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor  \n",
    "    ('rf', RandomForestClassifier(random_state=42))        #model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs4.best.score_: 0.8606498194945849\n",
      "gs4.best.params_: {'rf__max_depth': None, 'rf__max_features': 'auto', 'rf__n_estimators': 50, 'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 2, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...mators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params4 = {\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [2, 3, 5],\n",
    "    'tfidf__max_df': [.75, .8, .9, .95],\n",
    "    'rf__n_estimators': [10, 50, 100],  #to get rid of waranigs\n",
    "    'rf__max_depth': [None, 3, 5],\n",
    "    'rf__max_features': ['auto']  #auto is default\n",
    "   }   \n",
    "gs4 = GridSearchCV(pipe4, param_grid=params4, cv=5)\n",
    "gs4.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'gs4.best.score_: {gs4.best_score_}') # cross_val_score\n",
    "print(f'gs4.best.params_: {gs4.best_params_}')\n",
    "gs4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS4A: 0.9848375451263538\n",
      "Test Score GS4A: 0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS4A: {gs4.score(X_train,y_train)}')\n",
    "print(f'Test Score GS4A: {gs4.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs4.best.score_: 0.8418772563176895\n",
      "gs4.best.params_: {'rf__max_depth': 5, 'rf__max_features': 50, 'rf__n_estimators': 10, 'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...mators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params4 = {\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__max_features': [50],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [2, 3, 5],\n",
    "    'tfidf__max_df': [.75, .8, .9, .95],\n",
    "    'rf__n_estimators': [10],  #to get rid of waranigs\n",
    "    'rf__max_depth': [3, 5],\n",
    "    'rf__max_features': [50]  #auto is default\n",
    "   }   \n",
    "gs4 = GridSearchCV(pipe4, param_grid=params4, cv=5)\n",
    "gs4.fit(X_train, y_train)\n",
    "print(f'gs4.best.score_: {gs4.best_score_}') # cross_val_score\n",
    "print(f'gs4.best.params_: {gs4.best_params_}')\n",
    "gs4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS4B: 0.8570397111913357\n",
      "Test Score GS4B: 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS4B: {gs4.score(X_train,y_train)}')\n",
    "print(f'Test Score GS4B: {gs4.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section__ada\"></a>\n",
    "\n",
    "#### ADA with Tfidif\n",
    "\n",
    "[back](#section__scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning AdaBoostClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost with Tfidf\n",
    "pipe5 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor  \n",
    "    ('ada', AdaBoostClassifier())        #model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs5.best.score_: 0.8483754512635379\n",
      "gs5.best.params_: {'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params5 = {\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [2, 3, 5],\n",
    "    'tfidf__max_df': [.75, .8, .9, .95]\n",
    "    #'ada__n_estimators': [60,70,80],\n",
    "    #'ada__base_estimator__max_depth':[1,2],\n",
    "    #'ada__base_estimator__max_features':[None,10]    \n",
    "}\n",
    "gs5 = GridSearchCV(pipe5, param_grid=params5, cv=5)\n",
    "gs5.fit(X_train, y_train)\n",
    "\n",
    "print(f'gs5.best.score_: {gs5.best_score_}') # cross_val_score\n",
    "print(f'gs5.best.params_: {gs5.best_params_}')\n",
    "gs5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS5A: 0.9010830324909748\n",
      "Test Score GS5A: 0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS5A: {gs5.score(X_train,y_train)}')\n",
    "print(f'Test Score GS5A: {gs5.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs5.best.score_: 0.8483754512635379\n",
      "gs5.best.params_: {'tfidf__max_df': 0.75, 'tfidf__max_features': 50, 'tfidf__min_df': 3, 'tfidf__stop_words': 'english'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=50, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params5 = {\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'tfidf__max_features': [10, 25, 50],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [2, 3, 5],\n",
    "    'tfidf__max_df': [.75, .8, .9, .95]\n",
    "    #'ada__n_estimators': [60,70,80],\n",
    "    #'ada__base_estimator__max_depth':[1,2],\n",
    "    #'ada__base_estimator__max_features':[50]    \n",
    "}\n",
    "gs5 = GridSearchCV(pipe5, param_grid=params5, cv=5)\n",
    "gs5.fit(X_train, y_train)\n",
    "\n",
    "print(f'gs5.best.score_: {gs5.best_score_}') # cross_val_score\n",
    "print(f'gs5.best.params_: {gs5.best_params_}')\n",
    "gs5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score GS5B: 0.9010830324909748\n",
      "Test Score GS5B: 0.8831168831168831\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score GS5B: {gs5.score(X_train,y_train)}')\n",
    "print(f'Test Score GS5B: {gs5.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section__Model_Tuning'></a>\n",
    "\n",
    "####  Additional Tuning before deciding\n",
    "\n",
    "Having run through a variety of scenrios using the above, I determined that my best results were with Logistic Regression and Naive Bayes. I had not tried Naive Bayes with CountVectorize or LogisticRegression with Tfidif, so I decided to try these combinations, and test even more parameters to fine the best before deciding on a final model. It at first seemed GridSearch would always pick the max features I allow, and the min_df I allow. Through more experimentation I was able to find a combination that produced the best score, with parameters that fell in the middle of the ranges for which I tried, using Logistic Regression with Tfidif.  \n",
    "\n",
    "[back to top](#section__top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB best score_: 0.9588447653429603\n",
      "NB best params_: {'cvec__max_df': 0.5, 'cvec__max_features': 1500, 'cvec__min_df': 2, 'cvec__stop_words': 'english'}\n",
      "NB best estimator: Pipeline(memory=None,\n",
      "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=1500, min_df=2,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "NB Train Score: 0.9718411552346571\n",
      "NB Test Score: 0.9588744588744589\n",
      "NB Train - Test Score: = 0.012966696360198204\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes with CountVectorizer\n",
    "pipeNB = Pipeline([\n",
    "    ('cvec', CountVectorizer()),   #count vectorizor\n",
    "    ('mnb', MultinomialNB())        #model \n",
    "])\n",
    "paramsNB = {\n",
    "    'cvec__stop_words': ['english'],\n",
    "    'cvec__max_features': [1000, 1500],     \n",
    "    'cvec__min_df': [2, 2, 3],\n",
    "    'cvec__max_df': [.10, .25, .50, .75, .9]\n",
    "}\n",
    "gsNB = GridSearchCV(pipeNB, param_grid=paramsNB, cv=3)\n",
    "gsNB.fit(X_train, y_train) # Also does cv in the background\n",
    "\n",
    "print(f'NB best score_: {gsNB.best_score_}') # cross_val_score\n",
    "print(f'NB best params_: {gsNB.best_params_}')\n",
    "print(f'NB best estimator: {gsNB.best_estimator_}')\n",
    "nb_train_score = gsNB.score(X_train,y_train)\n",
    "nb_test_score = gsNB.score(X_test,y_test)\n",
    "nb_score_diff = gsNB.score(X_train,y_train) - gsNB.score(X_test,y_test)\n",
    "print(f'NB Train Score: {nb_train_score}')\n",
    "print(f'NB Test Score: {nb_test_score}')\n",
    "print(f'NB Train - Test Score: = {nb_score_diff}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR best score_: 0.9501805054151624\n",
      "LR best params_: {'lr__random_state': 42, 'tfidf__max_df': 0.25, 'tfidf__max_features': 2500, 'tfidf__min_df': 1, 'tfidf__stop_words': 'english'}\n",
      "LR Train Score: 0.9855595667870036\n",
      "LR Test Score: 0.9588744588744589\n",
      "LR Train - Test Score: = 0.026685107912544748\n",
      "Accuracy rate: 0.9588744588744589, misclassification rate: 0.04112554112554112\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression with Tfidif\n",
    "pipeLR = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor \n",
    "    ('lr', LogisticRegression())     #model \n",
    "])\n",
    "paramsLR = {\n",
    "    'lr__random_state': [42],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__max_features': [30, 50, 100, 500, 1500, 2000, 2500, 3000],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [1, 2, 3, 5],\n",
    "    'tfidf__max_df': [ .10, .25, .50, .75, .9]\n",
    "\n",
    "}\n",
    "gsLR = GridSearchCV(pipeLR, param_grid=paramsLR, cv=3)\n",
    "gsLR.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'LR best score_: {gsLR.best_score_}') # cross_val_score\n",
    "print(f'LR best params_: {gsLR.best_params_}')\n",
    "#print(f'LR best estimator: {gsLR.best_estimator_}')\n",
    "lr_train_score = gsLR.score(X_train,y_train)\n",
    "lr_test_score = gsLR.score(X_test,y_test)\n",
    "lr_score_diff = gsLR.score(X_train,y_train) - gsLR.score(X_test,y_test)\n",
    "print(f'LR Train Score: {lr_train_score}')\n",
    "print(f'LR Test Score: {lr_test_score}')\n",
    "print(f'LR Train - Test Score: = {lr_score_diff}')\n",
    "\n",
    "predictions = gsLR.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "misclassification = 1 - accuracy\n",
    "print(f'Accuracy rate: {accuracy}, misclassification rate: {misclassification}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final tuning of the chosen model\n",
    "Iterating over different parameter sets, looking for: \n",
    "-  Maximum scores\n",
    "-  Minimum difference between train and test score\n",
    "-  Maximum Accuracy of Predictions (Looking for 90%)\n",
    "-  All other things being equal, simplicity of model\n",
    "<br>\n",
    "\n",
    "\n",
    "Here is a snapshot of the different parameters that were tested. Following is a table that summarizes the results.\n",
    "\n",
    "```\n",
    "#Logistic regression with Tfidif\n",
    "pipeLR = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor \n",
    "    ('lr', LogisticRegression())     #model \n",
    "])\n",
    "paramsLR = {\n",
    "    'lr__random_state': [42],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__max_features': [30, 50, 100, 500, 1500, 2000, 2500, 3000],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [ 1, 2, 3, 5],\n",
    "    'tfidf__max_df': [ .10, .25, .50, .75, .9]\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|max_features|min_df|max_df|train score|test score|score diff|accuracy|notes|\n",
    "|------------|------|------|-----------|----------|----------|--------|-----|\n",
    "|50|1|.25|.889|.870|.0194|.870|\n",
    "|100|2|.5|.921|.900|.02|.90|\n",
    "|500|5|.5|.973|.961|.012|.961|This is the winner|\n",
    "|1500|2|.5|.984|.961|.023|.961|\n",
    "|2000|1|.25|.985|.958|.026|.958|\n",
    "|2500|1|.25|.985|.958|.026|.958|Hit max features, would not grow beyond|\n",
    "| 2000|   3 | .25 | .985 | .958|.026  | .958 | Constrained min_df to 3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* To improve on this workflow for the future, build a function to iterate through these options, and put the results metrics of interest in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward with the chosen model and the chosen best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR best score_: 0.940072202166065\n",
      "LR best params_: {'lr__random_state': 42, 'tfidf__max_df': 0.5, 'tfidf__max_features': 500, 'tfidf__min_df': 5, 'tfidf__stop_words': 'english'}\n",
      "LR Train Score: 0.9732851985559566\n",
      "LR Test Score: 0.961038961038961\n",
      "LR Train - Test Score: = 0.012246237516995606\n",
      "Accuracy rate: 0.961038961038961, misclassification rate: 0.038961038961038974\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression with Tfidif\n",
    "pipeLR = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),   #Tfidf vectorizor \n",
    "    ('lr', LogisticRegression())     #model \n",
    "])\n",
    "paramsLR = {\n",
    "    'lr__random_state': [42],\n",
    "    'tfidf__stop_words': ['english'],\n",
    "    'tfidf__max_features': [500],      #iterate over these options to see what is best\n",
    "    'tfidf__min_df': [5],\n",
    "    'tfidf__max_df': [.50]\n",
    "\n",
    "}\n",
    "gsLR = GridSearchCV(pipeLR, param_grid=paramsLR, cv=3)\n",
    "gsLR.fit(X_train, y_train) # Also does cv in the background\n",
    "print(f'LR best score_: {gsLR.best_score_}') # cross_val_score\n",
    "print(f'LR best params_: {gsLR.best_params_}')\n",
    "#print(f'LR best estimator: {gsLR.best_estimator_}')\n",
    "lr_train_score = gsLR.score(X_train,y_train)\n",
    "lr_test_score = gsLR.score(X_test,y_test)\n",
    "lr_score_diff = gsLR.score(X_train,y_train) - gsLR.score(X_test,y_test)\n",
    "print(f'LR Train Score: {lr_train_score}')\n",
    "print(f'LR Test Score: {lr_test_score}')\n",
    "print(f'LR Train - Test Score: = {lr_score_diff}')\n",
    "\n",
    "predictions = gsLR.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "misclassification = 1 - accuracy\n",
    "print(f'Accuracy rate: {accuracy}, misclassification rate: {misclassification}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section__Predictions'></a>\n",
    "\n",
    "### Predictions and Model Evaluation\n",
    "Let's see how our chosen model actually behaves on unseen data.\n",
    "\n",
    "<br>\n",
    "[back to top](#section__top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.961038961038961, misclassification rate: 0.038961038961038974\n"
     ]
    }
   ],
   "source": [
    "#generate predictions on the test data\n",
    "predictions = gsLR.predict(X_test)\n",
    "#get the true negative, false positive, false negative, and true positive \n",
    "#value from the confusion_matrix.\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "misclassification = 1 - accuracy\n",
    "print(f'Accuracy rate: {accuracy}, misclassification rate: {misclassification}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted r/travel</th>\n",
       "      <th>predicted other subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual r/travel</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other subreddits</th>\n",
       "      <td>14</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted r/travel  predicted other subreddits\n",
       "Actual r/travel                         256                           4\n",
       "Actual other subreddits                  14                         188"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the confusion matrix tavle\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(data=cm, columns=['predicted r/travel', \n",
    "                                       'predicted other subreddits'], \n",
    "                     index=['Actual r/travel', 'Actual other subreddits'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we do indeed have very few misclassified posts. We will examine those in detail below, but before we do, let's take a look at the classification report and the ROC Curve to get more insight into how our model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      travel       0.95      0.98      0.97       260\n",
      "  not travel       0.98      0.93      0.95       202\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       462\n",
      "   macro avg       0.96      0.96      0.96       462\n",
      "weighted avg       0.96      0.96      0.96       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions, target_names=['travel', 'not travel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "#thanks to James Hampton for the link\n",
    "model = gsLR\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.savefig('../images/roc.jpg');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the predicted probabilities for each new post. Look at the predict probas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'cleaned_post': X_test,\n",
    "                        'y_test': y_test,\n",
    "                        'prediction': predictions,\n",
    "                        'proba_not_travel': probs[:,0],\n",
    "                        'proba_travel': probs[:,1]})\n",
    "pred_df['misclassified'] = abs(pred_df['y_test'] - pred_df['prediction'])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_post</th>\n",
       "      <th>y_test</th>\n",
       "      <th>prediction</th>\n",
       "      <th>proba_not_travel</th>\n",
       "      <th>proba_travel</th>\n",
       "      <th>misclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>so i m going to europe uk for a few weeks and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.412025</td>\n",
       "      <td>0.587975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>while at the gym i notice people lean with the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942872</td>\n",
       "      <td>0.057128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>im using my vacation to travel to morocco this...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228280</td>\n",
       "      <td>0.771720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>my wife and i are traveling to spain this may ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074150</td>\n",
       "      <td>0.925850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>my neighbor recently put out a perfectly new w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972786</td>\n",
       "      <td>0.027214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_post  y_test  prediction  \\\n",
       "227   so i m going to europe uk for a few weeks and ...       1           1   \n",
       "997   while at the gym i notice people lean with the...       0           0   \n",
       "790   im using my vacation to travel to morocco this...       1           1   \n",
       "224   my wife and i are traveling to spain this may ...       1           1   \n",
       "1801  my neighbor recently put out a perfectly new w...       0           0   \n",
       "\n",
       "      proba_not_travel  proba_travel  misclassified  \n",
       "227           0.412025      0.587975              0  \n",
       "997           0.942872      0.057128              0  \n",
       "790           0.228280      0.771720              0  \n",
       "224           0.074150      0.925850              0  \n",
       "1801          0.972786      0.027214              0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_mask = pred_df['misclassified']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_df = pred_df[missed_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_post</th>\n",
       "      <th>y_test</th>\n",
       "      <th>prediction</th>\n",
       "      <th>proba_not_travel</th>\n",
       "      <th>proba_travel</th>\n",
       "      <th>misclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>hey all first time poster in this sub new job ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432670</td>\n",
       "      <td>0.567330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>i m looking to take or days to head into b c f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503158</td>\n",
       "      <td>0.496842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>i m heading to japan next week i ve heard rumo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428324</td>\n",
       "      <td>0.571676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>unaccompanied</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673257</td>\n",
       "      <td>0.326743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>as the title states i m looking for a hard she...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523562</td>\n",
       "      <td>0.476438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>hi guys apologies if this has been asked befor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559855</td>\n",
       "      <td>0.440145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>so my family and i are traveling tomorrow my w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.628338</td>\n",
       "      <td>0.371662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>my wife and i were hoping to visit israel and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633227</td>\n",
       "      <td>0.366773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>i ve got a simple problem but couldn t find an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633557</td>\n",
       "      <td>0.366443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>for the last several years my gf and i have be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.314038</td>\n",
       "      <td>0.685962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>i ve just traveled from philadelphia to dublin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505573</td>\n",
       "      <td>0.494427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>link to the game https earth google com web a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714721</td>\n",
       "      <td>0.285279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>i ve recently become super inclined to try dif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595155</td>\n",
       "      <td>0.404845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>hello so we are flying out to cancun airport a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593383</td>\n",
       "      <td>0.406617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>i ve tried several hotel search engines and i ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605213</td>\n",
       "      <td>0.394787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>title says it all hey all i am applying for my...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523589</td>\n",
       "      <td>0.476411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>hello all i am in need of some advice my gf an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196398</td>\n",
       "      <td>0.803602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>at gas stations throughout california they off...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655985</td>\n",
       "      <td>0.344015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_post  y_test  prediction  \\\n",
       "1498  hey all first time poster in this sub new job ...       0           1   \n",
       "116   i m looking to take or days to head into b c f...       1           0   \n",
       "1620  i m heading to japan next week i ve heard rumo...       0           1   \n",
       "370                                       unaccompanied       1           0   \n",
       "132   as the title states i m looking for a hard she...       1           0   \n",
       "133   hi guys apologies if this has been asked befor...       1           0   \n",
       "178   so my family and i are traveling tomorrow my w...       1           0   \n",
       "468   my wife and i were hoping to visit israel and ...       1           0   \n",
       "177   i ve got a simple problem but couldn t find an...       1           0   \n",
       "1748  for the last several years my gf and i have be...       0           1   \n",
       "759   i ve just traveled from philadelphia to dublin...       1           0   \n",
       "766   link to the game https earth google com web a ...       1           0   \n",
       "747   i ve recently become super inclined to try dif...       1           0   \n",
       "521   hello so we are flying out to cancun airport a...       1           0   \n",
       "195   i ve tried several hotel search engines and i ...       1           0   \n",
       "142   title says it all hey all i am applying for my...       1           0   \n",
       "1766  hello all i am in need of some advice my gf an...       0           1   \n",
       "360   at gas stations throughout california they off...       1           0   \n",
       "\n",
       "      proba_not_travel  proba_travel  misclassified  \n",
       "1498          0.432670      0.567330              1  \n",
       "116           0.503158      0.496842              1  \n",
       "1620          0.428324      0.571676              1  \n",
       "370           0.673257      0.326743              1  \n",
       "132           0.523562      0.476438              1  \n",
       "133           0.559855      0.440145              1  \n",
       "178           0.628338      0.371662              1  \n",
       "468           0.633227      0.366773              1  \n",
       "177           0.633557      0.366443              1  \n",
       "1748          0.314038      0.685962              1  \n",
       "759           0.505573      0.494427              1  \n",
       "766           0.714721      0.285279              1  \n",
       "747           0.595155      0.404845              1  \n",
       "521           0.593383      0.406617              1  \n",
       "195           0.605213      0.394787              1  \n",
       "142           0.523589      0.476411              1  \n",
       "1766          0.196398      0.803602              1  \n",
       "360           0.655985      0.344015              1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title says it all hey all i am applying for my first us passport and on the form it asks for mothers fathers name dob and birth place only my mom is listed on my birth certificate and when i asked her about dear ole dad she shrugged and said she didn t know or remember i m i ve never known my bio dad and have only known my step dad but he never adopted me what do i do for that question on the form the po is saying i got to put bio dads info there but what if i don t have it'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_df.loc[142]['cleaned_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = gsLR.best_estimator_.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = gsLR.best_estimator_.steps[0][1].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mod = gsLR.best_estimator_.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = lr_mod.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check size of coefficients and features list match: coefs: 500, features: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Check size of coefficients and features list match: coefs: {len(lr_coefs)}, features: {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Coefficients\n",
    "Create a dataframe to hold the coefficients for each feature, along with the odds of predicting a travel post given that feature appears in the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the coeffs and the features in a dataframe\n",
    "word_weight_df = pd.DataFrame({'word_features':feature_names,\n",
    "                              'coefs':lr_coefs})\n",
    "word_weight_df = word_weight_df.sort_values('coefs')\n",
    "#Calculate the odds\n",
    "word_weight_df['odds'] =  word_weight_df['coefs'].map(lambda x: np.exp(x) )\n",
    "#Create a column to help explain the odds\n",
    "#If the odds re between 0 and 1, the post is (1/odds -1) times less likely to be a travel post\n",
    "#If the odss are greater than 1, the post is odds-1 times more likely to be a travel post\n",
    "word_weight_df['odds explainer'] = word_weight_df['odds'].map(lambda x: (1/x)-1 if x < 1 else x-1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look strongest predictors for r/travel are at highest positive values, at the tail of the dataframe. Let' look at the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_features</th>\n",
       "      <th>coefs</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds explainer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>stay</td>\n",
       "      <td>1.737507</td>\n",
       "      <td>5.683160</td>\n",
       "      <td>4.683160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>country</td>\n",
       "      <td>1.816125</td>\n",
       "      <td>6.147987</td>\n",
       "      <td>5.147987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>planning</td>\n",
       "      <td>1.866739</td>\n",
       "      <td>6.467170</td>\n",
       "      <td>5.467170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>europe</td>\n",
       "      <td>1.918747</td>\n",
       "      <td>6.812416</td>\n",
       "      <td>5.812416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>visa</td>\n",
       "      <td>1.931882</td>\n",
       "      <td>6.902490</td>\n",
       "      <td>5.902490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>places</td>\n",
       "      <td>2.133818</td>\n",
       "      <td>8.447057</td>\n",
       "      <td>7.447057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>traveling</td>\n",
       "      <td>2.205422</td>\n",
       "      <td>9.074079</td>\n",
       "      <td>8.074079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>flight</td>\n",
       "      <td>3.017605</td>\n",
       "      <td>20.442277</td>\n",
       "      <td>19.442277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>trip</td>\n",
       "      <td>3.306685</td>\n",
       "      <td>27.294482</td>\n",
       "      <td>26.294482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>travel</td>\n",
       "      <td>3.480759</td>\n",
       "      <td>32.484379</td>\n",
       "      <td>31.484379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_features     coefs       odds  odds explainer\n",
       "403          stay  1.737507   5.683160        4.683160\n",
       "86        country  1.816125   6.147987        5.147987\n",
       "316      planning  1.866739   6.467170        5.467170\n",
       "124        europe  1.918747   6.812416        5.812416\n",
       "462          visa  1.931882   6.902490        5.902490\n",
       "312        places  2.133818   8.447057        7.447057\n",
       "444     traveling  2.205422   9.074079        8.074079\n",
       "149        flight  3.017605  20.442277       19.442277\n",
       "448          trip  3.306685  27.294482       26.294482\n",
       "443        travel  3.480759  32.484379       31.484379"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weight_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top ten predictors of a travel post certainly look like travel words. The number one predictor is the word 'travel' itself. If that appears in the post it is 31 times more likely to be in the travel thread. Likewise, if the word 'trip' appears in a post is it 26 times more likely to be in the travel post than if it did not appear. If the word 'flight' appears, it is 19 times more likely to be in travel, etc.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_features</th>\n",
       "      <th>coefs</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds explainer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>wine</td>\n",
       "      <td>-4.981654</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>144.715262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bottle</td>\n",
       "      <td>-2.315388</td>\n",
       "      <td>0.098728</td>\n",
       "      <td>9.128855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>gym</td>\n",
       "      <td>-2.044976</td>\n",
       "      <td>0.129383</td>\n",
       "      <td>6.728973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>plant</td>\n",
       "      <td>-1.919387</td>\n",
       "      <td>0.146697</td>\n",
       "      <td>5.816780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>wines</td>\n",
       "      <td>-1.814297</td>\n",
       "      <td>0.162952</td>\n",
       "      <td>5.136760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>garden</td>\n",
       "      <td>-1.684489</td>\n",
       "      <td>0.185539</td>\n",
       "      <td>4.389699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>workout</td>\n",
       "      <td>-1.519941</td>\n",
       "      <td>0.218725</td>\n",
       "      <td>3.571955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>weight</td>\n",
       "      <td>-1.471567</td>\n",
       "      <td>0.229565</td>\n",
       "      <td>3.356057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>tasting</td>\n",
       "      <td>-1.372867</td>\n",
       "      <td>0.253379</td>\n",
       "      <td>2.946650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>soil</td>\n",
       "      <td>-1.272236</td>\n",
       "      <td>0.280204</td>\n",
       "      <td>2.568824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_features     coefs      odds  odds explainer\n",
       "483          wine -4.981654  0.006863      144.715262\n",
       "45         bottle -2.315388  0.098728        9.128855\n",
       "179           gym -2.044976  0.129383        6.728973\n",
       "317         plant -1.919387  0.146697        5.816780\n",
       "484         wines -1.814297  0.162952        5.136760\n",
       "163        garden -1.684489  0.185539        4.389699\n",
       "490       workout -1.519941  0.218725        3.571955\n",
       "476        weight -1.471567  0.229565        3.356057\n",
       "418       tasting -1.372867  0.253379        2.946650\n",
       "384          soil -1.272236  0.280204        2.568824"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weight_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top ten words that lead us to classify a post as not travel are the negative coefficients at the top of the dataframe. If the word wine appears in a post is it 114 times less likely to be in the travel post than if it did not appear. If the word gym appears, it is 6 times less likely to be in travel, etc.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>3.48076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip</th>\n",
       "      <td>3.30668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flight</th>\n",
       "      <td>3.01761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveling</th>\n",
       "      <td>2.20542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>places</th>\n",
       "      <td>2.13382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visa</th>\n",
       "      <td>1.93188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>europe</th>\n",
       "      <td>1.91875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planning</th>\n",
       "      <td>1.86674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>1.81612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stay</th>\n",
       "      <td>1.73751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficients\n",
       "Features              \n",
       "travel         3.48076\n",
       "trip           3.30668\n",
       "flight         3.01761\n",
       "traveling      2.20542\n",
       "places         2.13382\n",
       "visa           1.93188\n",
       "europe         1.91875\n",
       "planning       1.86674\n",
       "country        1.81612\n",
       "stay           1.73751"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the coefficients for each variable and sor by abs val visuallize the predictive value of each\n",
    "##This code adapted from a sample provided by from James Hampton, and modified by Mark \n",
    "coef_df = pd.DataFrame([lr_coefs, feature_names], index = ['Coefficients', 'Features']).T\n",
    "coef_df = coef_df.set_index('Features')\n",
    "#coef_df['Coefficients'] = np.abs(coef_df['Coefficients'])\n",
    "coef_df = coef_df.sort_values(by='Coefficients',ascending=False)\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Strenth of Predictor')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(y=coef_df.index[:10], width=coef_df['Coefficients'][:10]);\n",
    "plt.title('Strongest Predictors of r/travel')\n",
    "plt.xlabel('Strenth of Predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = coef_df.shape[0] - 10\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Strenth of Predictor')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(y=coef_df.index[start:], width=coef_df['Coefficients'][start:]);\n",
    "plt.title('Strongest Predictor of not r/travel')\n",
    "plt.xlabel('Strenth of Predictor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section__Conclusion'></a>\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The model successfully classifies  r/travel, and not r/travel, with a 96% of the time!!!\n",
    "This is not surprising, though. These topics have very distinguishing words. It may have been much harder with more similar threads.\n",
    "It DOES do a good job of illustrating the classification techniques and the modeling process. \n",
    "Recommendation: DO HIRE DATA SCIENTISTS!!!!\n",
    "\n",
    "[back to top](#section__top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
